# Dockerfile
FROM openjdk:11-jdk-slim
LABEL authors="Botman-Hotman"

# Set environment variables for Spark and Hadoop
ENV SPARK_VERSION=3.4.0 \
    HADOOP_VERSION=3

# Install necessary tools and Python
RUN apt-get update && \
    apt-get install -y curl python3 python3-pip && \
    pip3 install pyspark

# Download and install Spark
RUN curl -L --silent "https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" | tar xz -C /opt && \
    mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark

# Set environment variables for Spark
ENV SPARK_HOME=/opt/spark
ENV PATH=$SPARK_HOME/bin:$PATH

# Expose Spark ports
EXPOSE 8080 7077 8081 4040

# Create a group and user with the same GID and UID
RUN groupadd -g 5678 appgroup && \
    useradd -u 5678 -g appgroup --no-log-init -m appuser

# Copy entrypoint script to the container
COPY entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh
RUN chown -R appuser:appgroup /opt/spark

# Switch to the non-root user
USER appuser

# Set entrypoint
ENTRYPOINT ["/entrypoint.sh"]